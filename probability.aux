\relax 
\providecommand\babel@aux[2]{}
\@nameuse{bbl@beforestart}
\babel@aux{greek}{}
\babel@aux{english}{}
\babel@aux{english}{}
\@writefile{toc}{\contentsline {chapter}{Index}{\EnsureStandardFontEncoding {iv}}{}\protected@file@percent }
\@writefile{toc}{\contentsline {chapter}{\numberline {1}Introduction}{1}{}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {1.1}The purpose of these notes}{1}{}\protected@file@percent }
\citation{spiegelhalter2019art}
\citation{degroot2012probability}
\citation{mcfadden2011philosophy}
\citation{openintro2025}
\citation{pishronik2014introduction}
\@writefile{toc}{\contentsline {section}{\numberline {1.2}A bit of history}{3}{}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {1.3}Warmup: some basic intuitions}{4}{}\protected@file@percent }
\newlabel{mean1}{{1.1}{4}{}{}{}}
\newlabel{mean2}{{1.2}{4}{}{}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {1.1}{\ignorespaces Histogram representing the mean and standard deviation for a set of gaussian observations. The read line shows the mean value, representing the central value where the bulk of events lie, and the dotted lines show the standard deviation, as measure of the variability, or how spread the observations are with respect to the mean.}}{5}{}\protected@file@percent }
\newlabel{fig:histogram1}{{1.1}{5}{}{}{}}
\@writefile{toc}{\contentsline {chapter}{\numberline {2}Probability and random events}{7}{}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {2.1}What is probability?}{7}{}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {2.2}Discrete probability distributions}{9}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2.1}Bernoulli distribution}{9}{}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {2.1}{\ignorespaces Representation of the bernoulli distribution of a random variable $x$, given the total number of trials $n$ and the individual probability of success $p$.}}{9}{}\protected@file@percent }
\newlabel{fig:bernoulli1}{{2.1}{9}{}{}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2.2}Binomial distribution}{10}{}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {2.2}{\ignorespaces Representation of the binomial distribution of a random variable $x$, given the total number of trials $n$ and the individual probability of success $p$.}}{10}{}\protected@file@percent }
\newlabel{fig:binomial1}{{2.2}{10}{}{}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2.3}Poisson distribution}{11}{}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {2.3}{\ignorespaces Representation of the Poisson distribution of a random variable $x$, given the number of observations $\lambda $ as a parameter.}}{11}{}\protected@file@percent }
\newlabel{fig:poisson1}{{2.3}{11}{}{}{}}
\@writefile{toc}{\contentsline {section}{\numberline {2.3}Discrete and continuous}{12}{}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {2.4}Continuous probability distributions}{13}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.4.1}Uniform distribution}{13}{}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {2.4}{\ignorespaces Representation of the uniform distribution of a random variable $x$, given the boundaries $a$, $b$.}}{13}{}\protected@file@percent }
\newlabel{fig:uniform1}{{2.4}{13}{}{}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.4.2}Gaussian distribution}{14}{}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {2.5}{\ignorespaces Representation of the gaussian distribution of a random variable $x$, given the mean value $\mu $ and standard deviation $\sigma $ parameters.}}{14}{}\protected@file@percent }
\newlabel{fig:gaussian1}{{2.5}{14}{}{}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.4.3}Exponential distribution}{15}{}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {2.6}{\ignorespaces Representation of the exponential distribution of a random variable $x$, given the decay rate $\lambda $.}}{15}{}\protected@file@percent }
\newlabel{fig:exponential1}{{2.6}{15}{}{}{}}
\@writefile{toc}{\contentsline {chapter}{\numberline {3}Parameter estimation}{19}{}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {3.1}Prediction vs inference}{19}{}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {3.2}Parameters and variables}{20}{}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {3.3}The Law of Large Numbers}{21}{}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {3.1}{\ignorespaces Representation of the law or large numbers. The sample mean tends to the population mean as the number of rolls $n$ increases.}}{21}{}\protected@file@percent }
\newlabel{fig:random}{{3.1}{21}{}{}{}}
\@writefile{toc}{\contentsline {section}{\numberline {3.4}The Central Limit Theorem}{22}{}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {3.2}{\ignorespaces Representation of the law or large numbers. The sample mean follows a gaussian distribution as the sample size $n$ increases.}}{22}{}\protected@file@percent }
\newlabel{fig:random}{{3.2}{22}{}{}{}}
\@writefile{toc}{\contentsline {section}{\numberline {3.5}Maximum Likelihood Estimation}{23}{}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Historical Context:}{23}{}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Why Maximum Likelihood?}{23}{}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Applications of MLE:}{23}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.5.1}Motivation and intuition}{23}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.5.2}The Likelihood and Log-Likelihood functions}{23}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.5.3}Properties of the MLE}{24}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.5.4}Application to Generalized Linear Models}{24}{}\protected@file@percent }
\citation{fisher1925}
\citation{fisher1935}
\citation{pearson1900}
\citation{pearson1900}
\@writefile{toc}{\contentsline {chapter}{\numberline {4}Introduction to hypothesis testing}{27}{}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {4.1}Prediction vs inference}{27}{}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {4.1}{\ignorespaces Representation of the predictive (from theory to experimental verification) and inferential (from data to underlying truth, descriptive and hypothesis testing) approaches to probability and statistics \cite  {pearson1900}.}}{27}{}\protected@file@percent }
\newlabel{fig:prob_vs_stats1}{{4.1}{27}{}{}{}}
\citation{fisher1925}
\citation{pearson1900}
\citation{welch1947}
\@writefile{toc}{\contentsline {section}{\numberline {4.2}Hypothesis, significance, p-values}{28}{}\protected@file@percent }
\citation{student1908}
\@writefile{toc}{\contentsline {section}{\numberline {4.3}Statistical tests: some examples}{29}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.3.1}Compare sample mean with hypothesized value - One sample t-test}{29}{}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {4.2}{\ignorespaces Representation of the t statistic, following the Student's t distribution, for a particular value of the degrees of freedom ($\nu = 10$). The integral of the shadowed area represents the \textit  {1-sided}, or \textit  {1-tailed} p-value, as the probability of obtaining a result \textit  {at least as extreme} as the one obtained $t_{obs}$.}}{29}{}\protected@file@percent }
\newlabel{fig:t_test1}{{4.2}{29}{}{}{}}
\citation{welch1947}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.3.2}Compare sample means of two independent groups - Two sample t-test}{31}{}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {4.3}{\ignorespaces Representation of the t statistic, following the Student's t distribution, for a particular value of the degrees of freedom ($\nu = 10$). The integral of the shadowed area represents the \textit  {2-sided}, or \textit  {2-tailed} p-value, as the probability of obtaining a result \textit  {at least as extreme} as the one obtained $t_{obs}$.}}{31}{}\protected@file@percent }
\newlabel{fig:t_test2}{{4.3}{31}{}{}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.4}{\ignorespaces Representation of the Student's t distribution, for different values of the degrees of freedom $\nu $.}}{32}{}\protected@file@percent }
\newlabel{fig:t_distribution}{{4.4}{32}{}{}{}}
\citation{welch1947}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.3.3}Compare sample variances of two groups - Fisher's exact test}{33}{}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {4.5}{\ignorespaces Representation of the F statistic, following the Fisher distribution, for a particular value of the degrees of freedom ($\nu = 10$). The integral of the shadowed area represents the \textit  {1-sided}, or \textit  {1-tailed} p-value, as the probability of obtaining a result \textit  {at least as extreme} as the one obtained $t_{obs}$.}}{33}{}\protected@file@percent }
\newlabel{fig:f_test1}{{4.5}{33}{}{}{}}
\citation{fisher1925}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.3.4}Compare variation on more than two groups - Fisher's ANOVA}{35}{}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {4.6}{\ignorespaces Representation of the F statistic, following the Fisher distribution, for a particular value of the degrees of freedom ($\nu = 10$). The integral of the shadowed area represents the \textit  {2-sided}, or \textit  {2-tailed} p-value, as the probability of obtaining a result \textit  {at least as extreme} as the one obtained $t_{obs}$.}}{35}{}\protected@file@percent }
\newlabel{fig:f_test2}{{4.6}{35}{}{}{}}
\citation{pearson1900}
\@writefile{lof}{\contentsline {figure}{\numberline {4.7}{\ignorespaces Representation of the Fisher distribution, for different values of the degrees of freedom $\nu _1$, $\nu _2$.}}{37}{}\protected@file@percent }
\newlabel{fig:f_distribution}{{4.7}{37}{}{}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.3.5}Compare distributions and testing for normality - $\chi ^{2}$ test}{37}{}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {4.8}{\ignorespaces Representation of the $chi^{2}$ statistic, following the Pearson $chi^{2}$ distribution, for a particular value of the degrees of freedom ($\nu = 10$). The integral of the shadowed area represents the \textit  {1-sided}, or \textit  {1-tailed} p-value, as the probability of obtaining a result \textit  {at least as extreme} as the one obtained $chi^{2}_{obs}$.}}{38}{}\protected@file@percent }
\newlabel{fig:chi2_test1}{{4.8}{38}{}{}{}}
\citation{student1908}
\citation{fisher1935}
\citation{fisher1925}
\citation{pearson1900}
\@writefile{lof}{\contentsline {figure}{\numberline {4.9}{\ignorespaces Representation of the $chi^{2}$ statistic, following the Pearson $chi^{2}$ distribution, for a particular value of the degrees of freedom ($\nu = 10$). The integral of the shadowed area represents the \textit  {2-sided}, or \textit  {2-tailed} p-value, as the probability of obtaining a result \textit  {at least as extreme} as the one obtained $chi^{2}_{obs}$.}}{39}{}\protected@file@percent }
\newlabel{fig:chi2_test2}{{4.9}{39}{}{}{}}
\@writefile{toc}{\contentsline {section}{\numberline {4.4}Parametric and non-parametric}{39}{}\protected@file@percent }
\citation{welch1947}
\@writefile{lof}{\contentsline {figure}{\numberline {4.10}{\ignorespaces Representation of the $chi^{2}$ distribution, for a particular value of the degrees of freedom ($\nu = 10$).}}{40}{}\protected@file@percent }
\newlabel{fig:chi2_distribution}{{4.10}{40}{}{}{}}
\@writefile{toc}{\contentsline {section}{\numberline {4.5}Comparing data and normalization}{41}{}\protected@file@percent }
\@writefile{toc}{\contentsline {chapter}{\numberline {5}Linear models and GLMs}{45}{}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {5.1}Simple linear regression}{45}{}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {5.2}Multiple linear regression}{46}{}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {5.3}Hypothesis testing in linear models}{47}{}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {5.4}Generalized Linear Models (GLMs)}{48}{}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {5.5}Logistic, Poisson, polynomial regression}{49}{}\protected@file@percent }
\@writefile{toc}{\contentsline {chapter}{\numberline {6}Introduction to bayesian probability}{53}{}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {6.1}Bayesian vs frequentist}{53}{}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {6.2}The Bayes' Rule}{54}{}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {6.3}Bayesian vs frequentist}{56}{}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {6.4}Computing posteriors}{57}{}\protected@file@percent }
\@writefile{toc}{\contentsline {chapter}{\numberline {7}Introduction to Markov processes}{59}{}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {7.1}Stochasticity and Markov processes}{59}{}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {7.2}Markov chains}{61}{}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {7.3}Hidden Markov models}{62}{}\protected@file@percent }
\@writefile{toc}{\contentsline {chapter}{\numberline {A}Algebra, vectors and matrices: a quick review}{65}{}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {A.1}The roots and rise of algebra}{65}{}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {A.2}Vectors and their properties}{67}{}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {A.3}Matrices and linear transformations}{68}{}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {A.4}Basic algebraic operations}{68}{}\protected@file@percent }
\@writefile{toc}{\contentsline {chapter}{\numberline {B}Calculus, functions and derivatives: a quick review}{69}{}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {B.1}From curves to calculus: functions}{70}{}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {B.1}{\ignorespaces Representation of a function $f(x)$, a given point $x_0$ and its image $f(x_0)$.}}{70}{}\protected@file@percent }
\newlabel{fig:functions_point_1}{{B.1}{70}{}{}{}}
\@writefile{toc}{\contentsline {section}{\numberline {B.2}The idea of change, slope and minima}{71}{}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {B.2}{\ignorespaces Representation of a function $f(x)$, a given point $x_0$ and its image $f(x_0)$, and an increment $\Delta x$ from $x_0$ to $x_0 + \Delta x$. The ratio between the increments in the horizontal axis, $\Delta x$, and the vertical axis $f(x_0 + \Delta x) - f(x_0)$ represents the derivative of the function at that point, that we denote by $f'(x_0)$.}}{71}{}\protected@file@percent }
\newlabel{fig:functions_point_2}{{B.2}{71}{}{}{}}
\@writefile{toc}{\contentsline {section}{\numberline {B.3}Derivatives}{72}{}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {B.3}{\ignorespaces Representation of a function $f(x)$, a given point $x_0$ and its image $f(x_0)$, and an increment $\Delta x$ from $x_0$ to $x_0 + \Delta x$. The ratio between the increments in the horizontal axis, $\Delta x$, and the vertical axis $f(x_0 + \Delta x) - f(x_0)$ represents the derivative of the function at that point, that we denote by $f'(x_0)$.}}{72}{}\protected@file@percent }
\newlabel{fig:functions_point_2_shadow}{{B.3}{72}{}{}{}}
\@writefile{toc}{\contentsline {chapter}{\numberline {C}Integrals: a quick review}{75}{}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{lof}{\contentsline {figure}{\numberline {C.1}{\ignorespaces Representation of a function $f(x)$, a given point $x_0$ and its image $f(x_0)$, and an increment $\Delta x$ from $x_0$ to $x_0 + \Delta x$.}}{76}{}\protected@file@percent }
\newlabel{fig:integrals_1}{{C.1}{76}{}{}{}}
\@writefile{toc}{\contentsline {section}{\numberline {C.1}Indefinite integral as antiderivative}{76}{}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {C.2}{\ignorespaces Representation of a function $f(x)$, a given point $x_0$ and its image $f(x_0)$, and an increment $\Delta x$ from $x_0$ to $x_0 + \Delta x$. Here we divide the $\Delta x$ increment in smaller steps, aiming to approximate the area under the function. As the subdivisions become smaller, they become a better approximation of the area, and in the limit $\Delta x \rightarrow \infty $ they converge to the Riemann definition.}}{77}{}\protected@file@percent }
\newlabel{fig:integrals_2}{{C.2}{77}{}{}{}}
\@writefile{toc}{\contentsline {section}{\numberline {C.2}Define definite integral as area under a curve}{77}{}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {C.3}The fundamental theorem of calculus}{77}{}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {C.3}{\ignorespaces Representation of a function $f(x)$, a given point $x_0$ and its image $f(x_0)$, and an increment $\Delta x$ from $x_0$ to $x_0 + \Delta x$. Here we divide the $\Delta x$ increment in smaller steps, aiming to approximate the area under the function. As the subdivisions become smaller, they become a better approximation of the area, and in the limit $\Delta x \rightarrow \infty $ they converge to the Riemann definition.}}{78}{}\protected@file@percent }
\newlabel{fig:integrals_2_subdivisions}{{C.3}{78}{}{}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {C.4}{\ignorespaces Representation of a function $f(x)$, a given point $x_0$ and its image $f(x_0)$, and an increment $\Delta x$ from $x_0$ to $x_0 + \Delta x$. Here we divide the $\Delta x$ increment in smaller steps, aiming to approximate the area under the function. As the subdivisions become smaller, they become a better approximation of the area, and in the limit $\Delta x \rightarrow \infty $ they converge to the Riemann definition.}}{78}{}\protected@file@percent }
\newlabel{fig:integrals_3_riemann}{{C.4}{78}{}{}{}}
\@writefile{toc}{\contentsline {chapter}{\numberline {D}Fourier series: a quick review}{79}{}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {D.1}Introduction to periodic functions}{80}{}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {D.2}Orthogonality and approximating functions}{80}{}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {D.1}{\ignorespaces Representation of a function $f(x)$, a given point $x_0$ and its image $f(x_0)$, and an increment $\Delta x$ from $x_0$ to $x_0 + \Delta x$.}}{81}{}\protected@file@percent }
\newlabel{fig:fourier_series_1}{{D.1}{81}{}{}{}}
\@writefile{toc}{\contentsline {section}{\numberline {D.3}Conditions of convergence}{81}{}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {D.4}Non-periodic functions}{81}{}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {D.2}{\ignorespaces Representation of a function $f(x)$, a given point $x_0$ and its image $f(x_0)$, and an increment $\Delta x$ from $x_0$ to $x_0 + \Delta x$. Here we divide the $\Delta x$ increment in smaller steps, aiming to approximate the area under the function. As the subdivisions become smaller, they become a better approximation of the area, and in the limit $\Delta x \rightarrow \infty $ they converge to the Riemann definition.}}{82}{}\protected@file@percent }
\newlabel{fig:fourier_series_2}{{D.2}{82}{}{}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {D.3}{\ignorespaces Representation of a function $f(x)$, a given point $x_0$ and its image $f(x_0)$, and an increment $\Delta x$ from $x_0$ to $x_0 + \Delta x$. Here we divide the $\Delta x$ increment in smaller steps, aiming to approximate the area under the function. As the subdivisions become smaller, they become a better approximation of the area, and in the limit $\Delta x \rightarrow \infty $ they converge to the Riemann definition.}}{82}{}\protected@file@percent }
\newlabel{fig:fourier_series_3}{{D.3}{82}{}{}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {D.4}{\ignorespaces Representation of a function $f(x)$, a given point $x_0$ and its image $f(x_0)$, and an increment $\Delta x$ from $x_0$ to $x_0 + \Delta x$.}}{83}{}\protected@file@percent }
\newlabel{fig:fourier_series_1}{{D.4}{83}{}{}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {D.5}{\ignorespaces Representation of a function $f(x)$, a given point $x_0$ and its image $f(x_0)$, and an increment $\Delta x$ from $x_0$ to $x_0 + \Delta x$. Here we divide the $\Delta x$ increment in smaller steps, aiming to approximate the area under the function. As the subdivisions become smaller, they become a better approximation of the area, and in the limit $\Delta x \rightarrow \infty $ they converge to the Riemann definition.}}{83}{}\protected@file@percent }
\newlabel{fig:fourier_series_2}{{D.5}{83}{}{}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {D.6}{\ignorespaces Representation of a function $f(x)$, a given point $x_0$ and its image $f(x_0)$, and an increment $\Delta x$ from $x_0$ to $x_0 + \Delta x$. Here we divide the $\Delta x$ increment in smaller steps, aiming to approximate the area under the function. As the subdivisions become smaller, they become a better approximation of the area, and in the limit $\Delta x \rightarrow \infty $ they converge to the Riemann definition.}}{84}{}\protected@file@percent }
\newlabel{fig:fourier_transform_3}{{D.6}{84}{}{}{}}
\bibcite{spiegelhalter2019art}{1}
\bibcite{degroot2012probability}{2}
\bibcite{mcfadden2011philosophy}{3}
\bibcite{openintro2025}{4}
\bibcite{pishronik2014introduction}{5}
\bibcite{student1908}{6}
\bibcite{fisher1925}{7}
\bibcite{fisher1935}{8}
\bibcite{pearson1900}{9}
\bibcite{welch1947}{10}
\bibcite{yates1934}{11}
\bibcite{greenwood1911}{12}
\gdef \@abspage@last{89}
